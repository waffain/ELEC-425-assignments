activation_tanh.m 
contains the tanh activation function

activation_tanh_gradient.m 
contains the derivative of the tanh function needed for backpropagation

compute_gradient_for_weights_and_one_layer_below.m 
helper function that calculates weight gradients and propagates error gradients backward during backpropagation

weighted_sum.m 
performs matrix multiplication between inputs and weights 

feedforward_net_tanh.m 
main script you run
